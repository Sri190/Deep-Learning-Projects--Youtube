{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635e816d-5009-4029-88f9-88bce6aaf812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5032.8813 - mae: 45.8372 - val_loss: 59.1550 - val_mae: 6.0311\n",
      "Epoch 2/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 40.3661 - mae: 4.8882 - val_loss: 8.5190 - val_mae: 2.2377\n",
      "Epoch 3/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.5401 - mae: 2.0408 - val_loss: 4.2394 - val_mae: 1.5389\n",
      "Epoch 4/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4.3797 - mae: 1.5432 - val_loss: 3.0771 - val_mae: 1.3158\n",
      "Epoch 5/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.1033 - mae: 1.3058 - val_loss: 2.5119 - val_mae: 1.2123\n",
      "Epoch 6/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.1754 - mae: 1.0950 - val_loss: 2.2401 - val_mae: 1.1497\n",
      "Epoch 7/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6652 - mae: 0.9685 - val_loss: 1.7787 - val_mae: 1.0430\n",
      "Epoch 8/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.3773 - mae: 0.8919 - val_loss: 1.5547 - val_mae: 0.9881\n",
      "Epoch 9/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.2437 - mae: 0.8507 - val_loss: 1.5513 - val_mae: 1.0063\n",
      "Epoch 10/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1704 - mae: 0.8273 - val_loss: 1.5724 - val_mae: 1.0203\n",
      "Epoch 11/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.0767 - mae: 0.7943 - val_loss: 1.4174 - val_mae: 0.9612\n",
      "Epoch 12/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9869 - mae: 0.7603 - val_loss: 1.0127 - val_mae: 0.7956\n",
      "Epoch 13/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8751 - mae: 0.7177 - val_loss: 0.7328 - val_mae: 0.6707\n",
      "Epoch 14/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7500 - mae: 0.6638 - val_loss: 0.7130 - val_mae: 0.6584\n",
      "Epoch 15/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6799 - mae: 0.6338 - val_loss: 0.8307 - val_mae: 0.7186\n",
      "Epoch 16/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6438 - mae: 0.6168 - val_loss: 0.9511 - val_mae: 0.7718\n",
      "Epoch 17/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6434 - mae: 0.6155 - val_loss: 0.9178 - val_mae: 0.7500\n",
      "Epoch 18/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6130 - mae: 0.6015 - val_loss: 0.7395 - val_mae: 0.6781\n",
      "Epoch 19/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5779 - mae: 0.5869 - val_loss: 0.7975 - val_mae: 0.7278\n",
      "Epoch 20/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5598 - mae: 0.5763 - val_loss: 0.9906 - val_mae: 0.8091\n",
      "Epoch 21/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5601 - mae: 0.5757 - val_loss: 1.1764 - val_mae: 0.8902\n",
      "Epoch 22/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5940 - mae: 0.5935 - val_loss: 1.3106 - val_mae: 0.9376\n",
      "Epoch 23/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5926 - mae: 0.5928 - val_loss: 1.3624 - val_mae: 0.9538\n",
      "Epoch 24/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6150 - mae: 0.6042 - val_loss: 1.3966 - val_mae: 0.9701\n",
      "Epoch 25/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5899 - mae: 0.5929 - val_loss: 1.4054 - val_mae: 0.9734\n",
      "Epoch 26/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5593 - mae: 0.5779 - val_loss: 1.5655 - val_mae: 1.0288\n",
      "Epoch 27/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5742 - mae: 0.5835 - val_loss: 1.5657 - val_mae: 1.0228\n",
      "Epoch 28/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5538 - mae: 0.5733 - val_loss: 1.6965 - val_mae: 1.0648\n",
      "Epoch 29/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5621 - mae: 0.5768 - val_loss: 1.5631 - val_mae: 1.0226\n",
      "Epoch 30/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5254 - mae: 0.5585 - val_loss: 1.4795 - val_mae: 0.9954\n",
      "Epoch 31/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5040 - mae: 0.5482 - val_loss: 1.3937 - val_mae: 0.9651\n",
      "Epoch 32/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4856 - mae: 0.5370 - val_loss: 1.4025 - val_mae: 0.9643\n",
      "Epoch 33/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.4794 - mae: 0.5343 - val_loss: 1.3789 - val_mae: 0.9576\n",
      "Epoch 34/200\n",
      "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4698 - mae: 0.5295 - val_loss: 1.3704 - val_mae: 0.9545\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6933 - mae: 0.6343\n",
      "Test Loss: 0.6986\n",
      "Test Mean Absolute Error: 0.6454\n"
     ]
    }
   ],
   "source": [
    "#Import All The Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(3)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#Data Cleaning\n",
    "df1=pd.read_csv(\"calories.csv\")\n",
    "df2=pd.read_csv(\"exercise.csv\")\n",
    "df=pd.concat([df2,df1['Calories']],axis=1)\n",
    "df['Gender']=df['Gender'].map({\"male\":1,\"female\":0})\n",
    "\n",
    "#Data Preprocessing\n",
    "scalar=StandardScaler()\n",
    "X=df.drop('Calories',axis=1)\n",
    "x=pd.DataFrame(scalar.fit_transform(X),columns=X.columns)\n",
    "y=df['Calories']\n",
    "\n",
    "#Train-Test Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "\n",
    "#Model Traininng\n",
    "model=keras.Sequential([\n",
    "    keras.layers.Input(shape=(8,)),\n",
    "    keras.layers.Dense(128,activation='relu'),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    keras.layers.Dense(1,activation='linear')])\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_split=0.1,epochs=200,batch_size=32,callbacks=[es])\n",
    "\n",
    "#Model Accuracy\n",
    "loss,mae=model.evaluate(x_test,y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Mean Absolute Error: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73445032-704d-4a6a-8084-8186101c3149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
