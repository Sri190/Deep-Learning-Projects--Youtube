{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec0eb577-a281-4088-8723-b47607eea4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 18.7173 - mae: 3.2971 - val_loss: 0.7014 - val_mae: 0.6658\n",
      "Epoch 2/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6156 - mae: 0.6152 - val_loss: 0.4128 - val_mae: 0.5110\n",
      "Epoch 3/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3940 - mae: 0.4917 - val_loss: 0.3300 - val_mae: 0.4602\n",
      "Epoch 4/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3202 - mae: 0.4423 - val_loss: 0.3165 - val_mae: 0.4534\n",
      "Epoch 5/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3003 - mae: 0.4273 - val_loss: 0.3116 - val_mae: 0.4477\n",
      "Epoch 6/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2927 - mae: 0.4210 - val_loss: 0.3067 - val_mae: 0.4396\n",
      "Epoch 7/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2881 - mae: 0.4177 - val_loss: 0.3057 - val_mae: 0.4357\n",
      "Epoch 8/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2858 - mae: 0.4163 - val_loss: 0.3043 - val_mae: 0.4328\n",
      "Epoch 9/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2839 - mae: 0.4153 - val_loss: 0.3025 - val_mae: 0.4303\n",
      "Epoch 10/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2823 - mae: 0.4147 - val_loss: 0.3047 - val_mae: 0.4330\n",
      "Epoch 11/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2817 - mae: 0.4145 - val_loss: 0.3044 - val_mae: 0.4330\n",
      "Epoch 12/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2813 - mae: 0.4144 - val_loss: 0.3061 - val_mae: 0.4348\n",
      "Epoch 13/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2814 - mae: 0.4145 - val_loss: 0.3112 - val_mae: 0.4392\n",
      "Epoch 14/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2802 - mae: 0.4136 - val_loss: 0.3093 - val_mae: 0.4386\n",
      "Epoch 15/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2790 - mae: 0.4128 - val_loss: 0.3104 - val_mae: 0.4403\n",
      "Epoch 16/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2785 - mae: 0.4124 - val_loss: 0.3121 - val_mae: 0.4422\n",
      "Epoch 17/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2774 - mae: 0.4117 - val_loss: 0.3131 - val_mae: 0.4435\n",
      "Epoch 18/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2776 - mae: 0.4116 - val_loss: 0.3142 - val_mae: 0.4443\n",
      "Epoch 19/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2766 - mae: 0.4110 - val_loss: 0.3144 - val_mae: 0.4447\n",
      "Epoch 20/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2758 - mae: 0.4103 - val_loss: 0.3152 - val_mae: 0.4453\n",
      "Epoch 21/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2751 - mae: 0.4098 - val_loss: 0.3161 - val_mae: 0.4457\n",
      "Epoch 22/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2745 - mae: 0.4092 - val_loss: 0.3175 - val_mae: 0.4471\n",
      "Epoch 23/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2734 - mae: 0.4084 - val_loss: 0.3168 - val_mae: 0.4465\n",
      "Epoch 24/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2726 - mae: 0.4076 - val_loss: 0.3178 - val_mae: 0.4469\n",
      "Epoch 25/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2717 - mae: 0.4070 - val_loss: 0.3180 - val_mae: 0.4469\n",
      "Epoch 26/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2710 - mae: 0.4063 - val_loss: 0.3189 - val_mae: 0.4473\n",
      "Epoch 27/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2701 - mae: 0.4053 - val_loss: 0.3205 - val_mae: 0.4483\n",
      "Epoch 28/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2701 - mae: 0.4054 - val_loss: 0.3212 - val_mae: 0.4489\n",
      "Epoch 29/200\n",
      "\u001b[1m216/216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2684 - mae: 0.4037 - val_loss: 0.3216 - val_mae: 0.4484\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2995 - mae: 0.4271\n",
      "Test Loss: 0.2883\n",
      "Test Mean Absolute Error: 0.4192\n"
     ]
    }
   ],
   "source": [
    "#Import all the Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(3)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import The dataset\n",
    "df=pd.read_csv(\"Train.csv\")\n",
    "\n",
    "#Filling the Missing Values\n",
    "def Mean_value(df,column):\n",
    "    mean_value=df[column].mean()\n",
    "    df.fillna({column:mean_value},inplace=True)\n",
    "def Mode_value(df,column):\n",
    "    mode_value=df[column].mode()[0]\n",
    "    df.fillna({column:mode_value},inplace=True)\n",
    "num_col=[col for col in df.columns if df[col].dtype==\"float64\"]\n",
    "odj_col=[col for col in df.columns if df[col].dtype==\"object\"]\n",
    "for col in odj_col:\n",
    "    Mode_value(df,col)\n",
    "for col in num_col:\n",
    "    Mean_value(df,col)\n",
    "\n",
    "#Label Encoding\n",
    "encoder=LabelEncoder()\n",
    "df['Item_Identifier']=encoder.fit_transform(df['Item_Identifier'])\n",
    "df['Item_Type']=encoder.fit_transform(df['Item_Type'])\n",
    "df['Item_Fat_Content']=encoder.fit_transform(df['Item_Fat_Content'])\n",
    "df['Outlet_Identifier']=encoder.fit_transform(df['Outlet_Identifier'])\n",
    "df['Outlet_Size']=encoder.fit_transform(df['Outlet_Size'])\n",
    "df['Outlet_Location_Type']=encoder.fit_transform(df['Outlet_Location_Type'])\n",
    "df['Outlet_Type']=encoder.fit_transform(df['Outlet_Type'])\n",
    "\n",
    "#Data Preprocessing\n",
    "scalar=StandardScaler()\n",
    "X=df.drop('Item_Outlet_Sales',axis=1)\n",
    "x=pd.DataFrame(scalar.fit_transform(X),columns=X.columns)\n",
    "y=np.log1p(df[\"Item_Outlet_Sales\"])\n",
    "\n",
    "#Train-test Split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=42)\n",
    "\n",
    "#Model Traininng\n",
    "model=keras.Sequential([\n",
    "    keras.layers.Input(shape=(11,)),\n",
    "    keras.layers.Dense(128,activation='relu'),\n",
    "    keras.layers.Dense(64,activation='relu'),\n",
    "    keras.layers.Dense(32,activation='relu'),\n",
    "    keras.layers.Dense(16,activation='relu'),\n",
    "    keras.layers.Dense(1,activation='linear')])\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['mae'])\n",
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "history = model.fit(x_train,y_train,validation_split=0.1,epochs=200,batch_size=32,callbacks=[es])\n",
    "\n",
    "#Model Accuracy\n",
    "loss,mae=model.evaluate(x_test,y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Mean Absolute Error: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd2343-5ba3-4abd-ba1a-ff1595f6a88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
